# 20180810 통계분석5

## 분산분석

- MEANING : 3개 이상의 집단에 대한 평균의 차이를 검증하는 분석
- EXAMPLE :  세 개의 커피전문점이 있다. 스타벅스, 이디야 그리고 투썸에서 아메리카노의 칼로리가 20kcal로 알려져있다. 하지만 절대미각인 내가 마셔본 결과 세 음료의 칼로리는 다르게 느껴진다. 전국 커피전문점에서 랜덤으로 50개의 매장에서 파는 아메리카노를 측정해봤다.

## 분산분석(ANOVA)

- 집단의 평균차이를 검정하기 위해서, 분산을 비교하는 분석 방법

집단 간의 분산과 집단 내의 분산을 확인하여 모집단의 특성을 찾아냄

- 집단 간의 분산이 클수록, 집단 내의 분산이 작을 수록 집단 간의 평균차이가 커짐
  -----> 집단 간의 상대적인 비율을 확인한 것을 분산비율 F라 함



## 실습(choco, choco2)

    import pandas as pd 
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns



- 가설설정

Ho = 스타벅스 kcal = 이디야 kcal = 투썸 kcal

(세 음료의 칼로리의 차이가 없다)

vs

H1 = 적어도 하나의 커피집은 같지 않다.

( 세 음료의 칼로리의 차이가 있다.)

- boxplot

![boxplot](https://user-images.githubusercontent.com/40633205/43948021-9b4366ba-9cc4-11e8-8ca5-b0397237b679.JPG)


세 커피전문점의 대표값이 서로 다르다는 것을 볼 수 있다.

- anova
![anova](https://user-images.githubusercontent.com/40633205/43948125-e2fdf2ae-9cc4-11e8-8060-3329e89175c7.JPG)
    이 자료는 F값이 9.413841이고 p값은 0.000142이므로 유의수준 0.05보다 작으므로 귀무가설을 기각한다.
  즉, 회귀모형이 의미가 있다는 뜻으로 세 커피집마다 커피집 칼로리가 다르다는 것으로 말할 수 있다.
- python code

    ```
    #### 각 카테고리 마다 칼럼이 있을 때
    
    choco = get_df('choco')
    choco.head()
    
    choco = choco.astype('int')
    choco.boxplot()
    
    from scipy import stats
    
    
    #output : F-statistics, p_value
    stats.f_oneway(choco['starbucks'], choco['ediya'], choco['twosome'])
    
    #### 카테고리에 해당하는 칼럼이 따로 있을 때
    choco2 = get_df('choco2')
    choco2.head()
    ![r](C:\Users\채송이\Pictures\ggg\r.JPG)
    choco2['kcal'] = choco2['kcal'].astype(int)
    choco2.boxplot('kcal', by='coffee')
    
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    
    model = ols("kcal ~ coffee", choco2).fit()
    sm.stats.anova_lm(model, typ=2)
    ```
## 상관분석

- 항상 산점도를 그려보고 분석을 시작해야한다.
- MEANING : 두 개의 연속형 변수에 대해서, 상관계수를 이용하여 선형 관계를 분석
- 상관계수 : 
  ![r](https://user-images.githubusercontent.com/40633205/43948178-127b94aa-9cc5-11e8-8055-cf0a659b6eaa.JPG)
  - 상관계수 범위: -1 ≤ r ≤ 1
  - r이 양수이면 양의 상관관계, 음수이면 음의 상관관계를 의미
  - 값의 크기는 선형관계의 강도를 의미
    r = ±1 : 완벽한 선형관계
    r = 0 : 선형관계가 없음
  
### 가설&검정
  
  ![default](https://user-images.githubusercontent.com/40633205/43948201-26fb5b86-9cc5-11e8-97ce-0c68105f4768.JPG)

귀무가설 : 상관계수 = 0, 두 자료의 상관관계가 없다.

대립가설 : 상관계수 ≠ 0, 두 자료의 상관관계가 있다.

------> 두 개의 연속형 변수의 모집단에서 상관계수가 0인지를 검정

### 실습

Q) 키가 크면 맥박수가 많아 지는지를 조사하고 있다. 이를 확인하기 위해

피 검사자 12명의 분당 맥박수와 신장(cm)을 수집하였다. 두 변수간의

관계를 확인하기 위해, 산점도를 그리고 상관분석을 진행하라.

pulse=c(69,68,70,71,73,71,74,69,70,73,69,70)

height=c(172,165,175,168,173,174,177,170,168,170,171,173)

![scatter](https://user-images.githubusercontent.com/40633205/43948225-41f9dcc8-9cc5-11e8-9952-56ecd0166692.JPG)

그래프로 봤을 때, 상관성이 크게 있어보이지는 않는다.

상관계수를 구해보니

0.5264152가 나왔다.  상관성은 어느정도있는 것으로 보인다.

- code
```
    from scipy import stats
    
    pulse = np.array([69,68,70,71,73,71,74,69,70,73,69,70])
    height = np.array([172,165,175,168,173,174,177,170,168,170,171,173])
    
    plt.scatter(pulse, height)
    #output : corr, p_value
    stats.pearsonr(pulse,height)
```
## 회귀분석

- meaning : 두 변수(즉, 독립변수와 종속변수) 사이 관계의 통계적 유의미성을 검증하고,
  또 그 관계의 정도를 분석하는 것
  - 독립변수, 설명변수(independent variable, explanatory variable, x)
  - 종속변수, 반응변수(dependent variable, response variable, y)
    

### regression분석의 기원

• ‘회귀(regression)’ : 옛날 상태로 돌아감 (go back to an earlier and worse condition)

• 영국의 유전학자인 갈톤 경이 부모의 키와 아이들의 키 사이의 연관 관계를 연구

• 부모와 자녀의 키사이에는 선형적인 관계가 있음

• 키는 무한정 커지거나 무한정 작아지는 것이 아니라 전체 키 평균으로 돌아가려는 경향이

있다는 것을 발견

• 그가 제안한 분석 방법의 이름을 ‘회귀’라 명명

![default](https://user-images.githubusercontent.com/40633205/43948678-69e4eb8c-9cc6-11e8-9cba-04cac22029d6.JPG)

### 선형/비선형의 의미

![default](https://user-images.githubusercontent.com/40633205/43948304-73209846-9cc5-11e8-81bf-e3bbf92a512a.JPG)

### 손으로 풀어보기

다중 선형 회귀분석은 계산이 복잡하므로 쉬운 단순 회귀분석을 풀어보자.

Q) 부모의 키가 크면 자식의 키도 클까? 알고 싶어져서 조사를 해봤다. 어머니의 키가 163cm일 때 딸의 키를 예측해보자.

![1](https://user-images.githubusercontent.com/40633205/43948725-94c1012e-9cc6-11e8-9a63-026620b766b3.jpg)

어머니의 키 140, 150, 155, 160, 165이다.

딸의 키 155,158,160, 163, 169이다.


![2](https://user-images.githubusercontent.com/40633205/43948750-a5ae9a00-9cc6-11e8-82be-a15022955dba.jpg)

barx는 154이고 bary는 161이다. x-barx랑 y-bary, (x-barx)(y-bary) 그리고 (x-barx)^2를 구하면 

![1 - 2](https://user-images.githubusercontent.com/40633205/43948773-bb7c5278-9cc6-11e8-9854-397383f6e3e6.jpg)

bo와 b1을 구할 수 있다.

![3](https://user-images.githubusercontent.com/40633205/43948804-d2a94c44-9cc6-11e8-8832-c6e088d163b2.jpg)

위와 같이 구하면 회귀선을 구할 수 있다. 회귀선에 어머니의 키(x)를 넣으면 딸의 키를 추정할 수 있다.

딸의 키는 165.74로 추정할 수 있다.

y값의 추정을 하였으면 예측구간을 구해야 한다.

![4](https://user-images.githubusercontent.com/40633205/43948830-dfeef228-9cc6-11e8-9dfd-6448b255ca9c.jpg)

신뢰수준은 90%로 정해주자. 그럼 a/2=0.05이고

자유도는 5-2=3이다. 해당 값을 t분포표로 찾으면 2.353이다.

![1](https://user-images.githubusercontent.com/40633205/43949009-5b1b4ca8-9cc7-11e8-974c-8b0462244bb4.JPG)

이 식에 y0(=딸의 추정 키), x0(=어머니의 추정 키)를 대입해준다.

![2](https://user-images.githubusercontent.com/40633205/43949037-69232708-9cc7-11e8-836a-ba5e8e2664f2.JPG)

계산을 해보면


![3](https://user-images.githubusercontent.com/40633205/43949074-79316a74-9cc7-11e8-895b-0a6ee6f52608.JPG)

이다. 즉 딸의 키의 예측구간은 (160.3202,171.1658)이다.

그러므로 어머니의 키가 163cm일 때, 딸의 키는 160.3202에서 171.1658사이 일것이다. 라고 예측할 수 있다.



무엇가를 예측 할 때, "161cm일 것이다."는 맞을 확률이 거의 없다고 한다. 하지만

구간으로 설정해 놓고  "키는 160.3202에서 171.1658사이 일것이다."라 예측하면 맞을 확률이 올라간다. 그래서 점추정보다는 구간추정로 예측하는 것이 좋다.

### 실습 - 보스턴 집값

![1](https://user-images.githubusercontent.com/40633205/43948259-5a760dd0-9cc5-11e8-88a1-b827ea54fc7a.JPG)

보스턴 집값의 자료이다.

![default](https://user-images.githubusercontent.com/40633205/43949115-8e12bea2-9cc7-11e8-9b26-45a11379dc5b.JPG)

    # 실제 y(medv) 값과 예측한 y(medv) 값의 산점도를 그렸을 시, y=x 형태에 가까울수록 예측이 잘 된 것
    plt.scatter(x= df['Actual'],y = df['Predicted'])
    plt.plot(np.arange(0, 50), np.arange(0, 50), color = "red")
    plt.show()



여기서 어떤 변수가 의미가 있는지 회귀선을 추정해 보겠다.

    model = ols(formula = "medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat", data = boston).fit()
    model.summary()


![default](https://user-images.githubusercontent.com/40633205/43949277-0b68ca04-9cc8-11e8-8ab3-993e9b7e59de.png)

이런 값이 나왔다.  노란색으로 칠한 부분이 회귀계수이다.



이런 식으로 회귀식을 구할 수 있다. 노란색부분이 회귀계수 옆에 intercept, crim 등등이 변수이다.

이 식을 보니 crim, nox, dis 등등 같이 -(마이너스)를 띄는 회귀계수들은 음의  관계를 띈다고 할 수 있다.

위 자료에서 빨간색을 칠한 부분은 유의수준 0.05를 넘는다. 즉 계수들이 유의미하지 않다는 뜻이다. 

### 회귀분석의 가정

- 선형성
  - 그림을 통해(선점도) 파악
- 정규성
  - 히스토그램, 정규확률도를 통해 파악
- 다중공선성
  - x(독립변수)들 간의 상관계수가 높은 상황
  - vif(=다중공선성)이 커지면 유의한 회귀계수가 의미없다고 판단 될 수 있다.
  - 해결법
    - 상관관계가 높은 독립변수 중 하나를 제거
    - 변수 변환
    - pca(=주성분 분석을 이용해 공선성 제거
